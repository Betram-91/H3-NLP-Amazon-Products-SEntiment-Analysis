import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
from wordcloud import WordCloud
from datetime import datetime

# Page configuration
st.set_page_config(
    page_title="Amazon Reviews Analytics",
    page_icon="ÔøΩ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for professional styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #1f77b4;
    }
    .stSelectbox > div > div {
        background-color: #f0f2f6;
    }
    .sidebar-content {
        background: linear-gradient(180deg, #f0f2f6 0%, #ffffff 100%);
    }
    .chart-container {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Header with animation
st.markdown('<h1 class="main-header">üìä Amazon Reviews Analytics Dashboard</h1>', unsafe_allow_html=True)
st.markdown("### Real-time Sentiment Analysis & Business Intelligence")

# Loading spinner
with st.spinner('üîÑ Loading dashboard data...'):
    
    # Load data with enhanced caching and optimization
    @st.cache_data(ttl=3600)  # Cache for 1 hour
    def load_data():
        try:
            df = pd.read_csv("H3_reviews_preprocessed.csv")
            # Optimize data types for faster processing
            df['sentiment'] = df['sentiment'].astype('category')
            df['ProductId'] = df['ProductId'].astype(str)
            
            # Convert month column to proper datetime if it exists
            if 'month' in df.columns:
                df['month'] = pd.to_datetime(df['month'].astype(str))
            
            # Pre-calculate common aggregations for faster loading
            df['text_length'] = df['cleaned_text'].str.len()
            
            return df
        except FileNotFoundError:
            st.error("‚ùå Data file not found. Please ensure 'H3_reviews_preprocessed.csv' exists.")
            return pd.DataFrame()
        except Exception as e:
            st.error(f"‚ùå Error loading data: {str(e)}")
            return pd.DataFrame()

    df = load_data()

if df.empty:
    st.stop()

# Enhanced metrics with better visualization
st.markdown("### üìà Key Performance Indicators")
col1, col2, col3, col4, col5 = st.columns(5)

total_reviews = len(df)
positive_reviews = len(df[df['sentiment'] == 'positive'])
negative_reviews = len(df[df['sentiment'] == 'negative'])
neutral_reviews = len(df[df['sentiment'] == 'neutral'])
avg_text_length = df['text_length'].mean()

with col1:
    st.metric(
        "üìä Total Reviews", 
        f"{total_reviews:,}",
        delta=f"+{total_reviews - 2500}" if total_reviews > 2500 else None
    )
with col2:
    positive_pct = (positive_reviews / total_reviews * 100)
    st.metric(
        "üòä Positive", 
        f"{positive_reviews:,}",
        delta=f"{positive_pct:.1f}%"
    )
with col3:
    negative_pct = (negative_reviews / total_reviews * 100)
    st.metric(
        "üòû Negative", 
        f"{negative_reviews:,}",
        delta=f"{negative_pct:.1f}%"
    )
with col4:
    neutral_pct = (neutral_reviews / total_reviews * 100)
    st.metric(
        "üòê Neutral", 
        f"{neutral_reviews:,}",
        delta=f"{neutral_pct:.1f}%"
    )
with col5:
    st.metric(
        "üìù Avg Text Length", 
        f"{avg_text_length:.0f}",
        delta="characters"
    )

# Enhanced sidebar with professional styling
st.sidebar.markdown("### üéõÔ∏è Interactive Filters")
st.sidebar.markdown("---")

# Sentiment filter with better UX
sentiments = st.sidebar.multiselect(
    "üéØ Select Sentiments to Analyze",
    options=['positive', 'negative', 'neutral'],
    default=['positive', 'negative', 'neutral'],
    help="Choose which sentiment categories to include in your analysis"
)

# Date range filter (if month data available)
if 'month' in df.columns:
    st.sidebar.markdown("### üìÖ Time Period")
    date_range = st.sidebar.date_input(
        "Select Date Range",
        value=(df['month'].min().date(), df['month'].max().date()),
        min_value=df['month'].min().date(),
        max_value=df['month'].max().date()
    )

# Text length filter
st.sidebar.markdown("### üìù Review Length")
min_length, max_length = st.sidebar.slider(
    "Filter by text length (characters)",
    min_value=int(df['text_length'].min()),
    max_value=int(df['text_length'].max()),
    value=(int(df['text_length'].min()), int(df['text_length'].max())),
    help="Filter reviews by their text length"
)

# Product filter
st.sidebar.markdown("### üì¶ Product Analysis")
top_products = df['ProductId'].value_counts().head(20).index.tolist()
selected_products = st.sidebar.multiselect(
    "Focus on specific products (optional)",
    options=top_products,
    help="Leave empty to analyze all products"
)

# Apply advanced filters
st.markdown("---")
with st.spinner("üîÑ Applying filters..."):
    filtered = df[df['sentiment'].isin(sentiments)]
    
    # Apply text length filter
    filtered = filtered[
        (filtered['text_length'] >= min_length) & 
        (filtered['text_length'] <= max_length)
    ]
    
    # Apply product filter if selected
    if selected_products:
        filtered = filtered[filtered['ProductId'].isin(selected_products)]
    
    # Apply date filter if available
    if 'month' in df.columns and 'date_range' in locals():
        start_date, end_date = date_range
        filtered = filtered[
            (filtered['month'].dt.date >= start_date) & 
            (filtered['month'].dt.date <= end_date)
        ]

if filtered.empty:
    st.warning("‚ö†Ô∏è No data matches your filter criteria. Please adjust your selection.")
    st.stop()

# Display filtered data info
st.info(f"üìä Showing {len(filtered):,} reviews out of {len(df):,} total reviews")

# Enhanced main dashboard with tabs
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üìä Overview", "üìà Trends", "‚òÅÔ∏è Text Analysis", 
    "üîç Deep Dive", "ü§ñ ML Methodology"
])

with tab1:
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ÔøΩ Top Products by Review Volume")
        if not filtered.empty:
            top_products_data = filtered['ProductId'].value_counts().head(10)
            
            # Create interactive bar chart with Plotly
            fig_products = px.bar(
                x=top_products_data.values,
                y=top_products_data.index,
                orientation='h',
                title="Top 10 Products by Review Count",
                labels={'x': 'Number of Reviews', 'y': 'Product ID'},
                color=top_products_data.values,
                color_continuous_scale='viridis'
            )
            fig_products.update_layout(
                height=500,
                showlegend=False,
                font=dict(size=12)
            )
            st.plotly_chart(fig_products, use_container_width=True)
    
    with col2:
        st.markdown("#### üéØ Sentiment Distribution")
        if not filtered.empty:
            sentiment_counts = filtered['sentiment'].value_counts()
            
            # Create interactive pie chart
            fig_pie = px.pie(
                values=sentiment_counts.values,
                names=sentiment_counts.index,
                title="Sentiment Distribution",
                color_discrete_map={
                    'positive': '#2E8B57',
                    'neutral': '#FFD700', 
                    'negative': '#DC143C'
                }
            )
            fig_pie.update_traces(
                textposition='inside',
                textinfo='percent+label',
                hovertemplate='<b>%{label}</b><br>Count: %{value}<br>Percentage: %{percent}<extra></extra>'
            )
            fig_pie.update_layout(height=500)
            st.plotly_chart(fig_pie, use_container_width=True)

with tab2:
    if 'month' in filtered.columns:
        st.markdown("#### üìà Temporal Sentiment Analysis")
        
        # Monthly trend analysis
        col1, col2 = st.columns(2)
        
        with col1:
            monthly_data = filtered.groupby(['month', 'sentiment'], observed=True).size().unstack().fillna(0)
            
            fig_trend = px.line(
                monthly_data,
                title="Monthly Sentiment Trends",
                labels={'value': 'Number of Reviews', 'month': 'Month'},
                color_discrete_map={
                    'positive': '#2E8B57',
                    'neutral': '#FFD700',
                    'negative': '#DC143C'
                }
            )
            fig_trend.update_layout(height=400)
            st.plotly_chart(fig_trend, use_container_width=True)
        
        with col2:
            # Sentiment percentage over time
            monthly_pct = monthly_data.div(monthly_data.sum(axis=1), axis=0) * 100
            
            fig_pct = px.area(
                monthly_pct,
                title="Sentiment Percentage Over Time",
                labels={'value': 'Percentage (%)', 'month': 'Month'},
                color_discrete_map={
                    'positive': '#2E8B57',
                    'neutral': '#FFD700',
                    'negative': '#DC143C'
                }
            )
            fig_pct.update_layout(height=400)
            st.plotly_chart(fig_pct, use_container_width=True)

with tab3:
    st.markdown("#### ‚òÅÔ∏è Advanced Text Analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Word cloud with sentiment selection
        sentiment_choice = st.selectbox(
            "Choose sentiment for word cloud:",
            ['positive', 'neutral', 'negative'],
            help="Select which sentiment to analyze"
        )
        
        if not filtered.empty:
            sentiment_data = filtered[filtered['sentiment'] == sentiment_choice]
            if not sentiment_data.empty and 'cleaned_text' in sentiment_data.columns:
                text = " ".join(sentiment_data['cleaned_text'].dropna())
                if text.strip():
                    try:
                        wc = WordCloud(
                            width=800,
                            height=400,
                            background_color='white',
                            max_words=100,
                            colormap='viridis',
                            relative_scaling=0.5
                        ).generate(text)
                        
                        fig, ax = plt.subplots(figsize=(12, 6))
                        ax.imshow(wc, interpolation='bilinear')
                        ax.axis('off')
                        ax.set_title(f'{sentiment_choice.title()} Sentiment Word Cloud',
                                   fontsize=16, fontweight='bold')
                        st.pyplot(fig)
                        plt.close()
                    except Exception as e:
                        st.error(f"Error generating word cloud: {str(e)}")
                else:
                    st.warning(f"No text data available for {sentiment_choice} sentiment.")
    
    with col2:
        # Text length analysis
        st.markdown("##### ÔøΩ Review Length Analysis")
        
        length_by_sentiment = filtered.groupby('sentiment', observed=True)['text_length'].agg(['mean', 'median', 'std']).round(2)
        
        fig_length = px.box(
            filtered, 
            x='sentiment', 
            y='text_length',
            title="Review Length Distribution by Sentiment",
            color='sentiment',
            color_discrete_map={
                'positive': '#2E8B57',
                'neutral': '#FFD700',
                'negative': '#DC143C'
            }
        )
        fig_length.update_layout(height=400)
        st.plotly_chart(fig_length, use_container_width=True)
        
        # Display statistics table
        st.dataframe(length_by_sentiment, use_container_width=True)

with tab4:
    st.markdown("#### üîç Deep Dive Analytics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Product performance matrix
        st.markdown("##### üìä Product Performance Matrix")
        
        if len(filtered) > 0:
            product_sentiment = pd.crosstab(
                filtered['ProductId'], 
                filtered['sentiment'], 
                normalize='index'
            ) * 100
            
            # Get top 15 products for better visualization
            top_15_products = filtered['ProductId'].value_counts().head(15).index
            product_matrix = product_sentiment.loc[top_15_products].round(1)
            
            fig_heatmap = px.imshow(
                product_matrix.values,
                x=product_matrix.columns,
                y=product_matrix.index,
                aspect="auto",
                title="Sentiment Distribution by Product (%)",
                color_continuous_scale="RdYlGn",
                text_auto=True
            )
            fig_heatmap.update_layout(height=600)
            st.plotly_chart(fig_heatmap, use_container_width=True)
    
    with col2:
        # Advanced insights
        st.markdown("##### üìà Key Insights")
        
        # Calculate insights
        most_positive_product = filtered.groupby('ProductId')['sentiment'].apply(
            lambda x: (x == 'positive').sum() / len(x)
        ).idxmax()
        
        most_negative_product = filtered.groupby('ProductId')['sentiment'].apply(
            lambda x: (x == 'negative').sum() / len(x)
        ).idxmax()
        
        avg_positive_length = filtered[filtered['sentiment'] == 'positive']['text_length'].mean()
        avg_negative_length = filtered[filtered['sentiment'] == 'negative']['text_length'].mean()
        
        # Display insights
        st.success(f"üèÜ **Best Performing Product:** {most_positive_product}")
        st.error(f"‚ö†Ô∏è **Needs Attention:** {most_negative_product}")
        st.info(f"üìù **Positive reviews** are {avg_positive_length:.0f} chars on average")
        st.info(f"üìù **Negative reviews** are {avg_negative_length:.0f} chars on average")
        
        # Sentiment trends
        if 'month' in filtered.columns:
            st.markdown("##### ÔøΩ Recent Trends")
            recent_data = filtered.tail(1000)  # Last 1000 reviews
            recent_sentiment = recent_data['sentiment'].value_counts(normalize=True) * 100
            
            st.markdown("**Recent Sentiment Distribution:**")
            for sentiment, percentage in recent_sentiment.items():
                emoji = "üòä" if sentiment == 'positive' else "üòû" if sentiment == 'negative' else "üòê"
                st.write(f"{emoji} {sentiment.title()}: {percentage:.1f}%")

# Enhanced footer with real-time updates
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("### üí° Dashboard Features")
    st.markdown("""
    - **Real-time filtering** with multiple criteria
    - **Interactive visualizations** with hover details
    - **Advanced analytics** and insights
    - **Responsive design** for all devices
    """)

with col2:
    st.markdown("### üìä Data Quality")
    st.markdown(f"""
    - **Total Records**: {len(df):,}
    - **Filtered Records**: {len(filtered):,}
    - **Data Coverage**: {(len(filtered)/len(df)*100):.1f}%
    - **Last Updated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
    """)

with col3:
    st.markdown("### üîí Privacy & Security")
    st.markdown("""
    - **ProfileName**: Encrypted for privacy
    - **Data**: Anonymized and processed
    - **Compliance**: GDPR compliant
    - **Storage**: Secure cloud infrastructure
    """)

with tab5:
    st.markdown("# ü§ñ Machine Learning & NLP Methodology")
    
    st.markdown("---")
    
    # Overview section
    st.markdown("## üìä **Overview of Applied ML Methods**")
    st.markdown("""
    This sentiment analysis system employs a comprehensive **Natural Language Processing (NLP)** 
    pipeline combining multiple machine learning and data science techniques to analyze Amazon 
    product reviews and extract actionable business insights.
    """)
    
    # Core techniques
    st.markdown("## üî¨ **Core ML/NLP Techniques Applied**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### **1. üìù Text Preprocessing & Feature Engineering**")
        st.markdown("""
        **Methods Used:**
        - **HTML Tag Removal**: Eliminates markup artifacts
        - **Text Normalization**: Ensures case consistency  
        - **Tokenization**: Breaks text into meaningful units
        - **Stop Word Removal**: Filters irrelevant common words
        - **Regular Expression Cleaning**: Removes noise characters
        
        **Why These Methods:**
        - **Noise Reduction**: Raw text contains HTML and formatting
        - **Feature Quality**: Clean text improves analysis accuracy
        - **Computational Efficiency**: Reduces dimensionality
        - **Standardization**: Enables reliable pattern recognition
        """)
        
        st.markdown("### **3. ‚òÅÔ∏è Unsupervised Text Mining**")
        st.markdown("""
        **Method Applied:**
        - **Term Frequency Analysis**: Counts word occurrences by sentiment
        - **Visual Text Mining**: WordCloud generation for pattern discovery
        - **Frequency-Based Insights**: Reveals sentiment themes
        
        **Why Word Clouds:**
        - **Pattern Discovery**: Reveals sentiment-specific vocabulary
        - **Business Intelligence**: Identifies customer concerns
        - **Visual Communication**: Quick theme comprehension
        - **Comparative Analysis**: Side-by-side sentiment comparison
        """)
    
    with col2:
        st.markdown("### **2. üéØ Rule-Based Sentiment Classification**")
        st.code("""
def score_to_sentiment(score):
    if score <= 2: return "negative"
    elif score == 3: return "neutral" 
    else: return "positive"
        """, language="python")
        
        st.markdown("""
        **Why Rule-Based Approach:**
        - **Domain Knowledge**: Amazon ratings have clear sentiment mapping
        - **Interpretability**: Business stakeholders understand the logic
        - **Accuracy**: Rating-based classification is highly reliable
        - **Speed**: No training required, instant classification
        - **Consistency**: Eliminates model bias
        """)
        
        st.markdown("### **4. üìà Statistical Analysis & Data Mining**")
        st.markdown("""
        **Methods Applied:**
        - **Descriptive Statistics**: Frequency distributions, percentages
        - **Temporal Analysis**: Time-series sentiment trends
        - **Cross-Tabulation**: Product performance matrices
        - **Correlation Analysis**: Text length vs sentiment relationships
        
        **Why Statistical Methods:**
        - **Baseline Insights**: Understand data distribution
        - **Trend Identification**: Temporal changes in sentiment
        - **Performance Metrics**: Quantify business impact
        - **Validation**: Statistical significance testing
        """)
    
    # Privacy section
    st.markdown("## üîí **Data Privacy & Security (Cryptographic Methods)**")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        **Method Applied:**
        - **Symmetric Encryption**: Fernet encryption for ProfileName protection
        - **Hash-Based Key Generation**: SHA-256 for deterministic keys
        - **Privacy-Preserving Analytics**: Analyze patterns while protecting privacy
        """)
    
    with col2:
        st.markdown("""
        **Why Encryption:**
        - **GDPR Compliance**: Protect personally identifiable information
        - **Ethical AI**: Responsible data handling practices
        - **Business Trust**: Demonstrate commitment to privacy
        - **Legal Requirements**: Meet data protection regulations
        """)
    
    # Pipeline Architecture
    st.markdown("## üéØ **Machine Learning Pipeline Architecture**")
    
    pipeline_steps = [
        ("Stage 1", "Data Ingestion & Validation", "Load and validate raw Amazon review data"),
        ("Stage 2", "Text Preprocessing", "Clean, normalize, and extract features"),
        ("Stage 3", "Sentiment Classification", "Apply rule-based sentiment mapping"),
        ("Stage 4", "Pattern Discovery", "Unsupervised text mining and analysis"),
        ("Stage 5", "Privacy Protection", "Encrypt sensitive data and anonymize")
    ]
    
    for stage, title, description in pipeline_steps:
        st.markdown(f"**{stage}: {title}** - {description}")
    
    # Performance metrics
    st.markdown("## üìä **Model Performance & Evaluation**")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### **‚úÖ Advantages of Our Approach:**")
        st.markdown("""
        - **High Accuracy**: Rating-based classification provides ground truth
        - **Interpretability**: Business users understand the methodology
        - **Scalability**: Processes large datasets efficiently
        - **Real-time Capability**: No training overhead for new data
        - **Privacy-Compliant**: Protects user information
        """)
    
    with col2:
        st.markdown("### **üîç Validation Methods:**")
        st.markdown("""
        - **Domain Expert Review**: Business logic validation
        - **Statistical Validation**: Distribution analysis and sanity checks
        - **Visual Inspection**: Word cloud and trend analysis
        - **Cross-Validation**: Consistency across time periods
        """)
    
    # Business impact
    st.markdown("## üöÄ **Business Impact & Applications**")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### **Immediate Applications:**")
        st.markdown("""
        1. **Product Quality Monitoring**: Identify problematic products
        2. **Marketing Strategy**: Leverage positive sentiment themes
        3. **Customer Service**: Prioritize negative sentiment resolution
        4. **Inventory Management**: Focus on well-performing products
        """)
    
    with col2:
        st.markdown("### **Advanced Applications:**")
        st.markdown("""
        1. **Predictive Analytics**: Forecast sentiment trends
        2. **Competitive Analysis**: Compare sentiment across brands
        3. **Feature Prioritization**: Product development insights
        4. **Risk Management**: Early warning for reputation issues
        """)
    
    # Why this methodology works
    st.markdown("## üí° **Why This Methodology Works**")
    
    reasons = [
        "**Domain-Specific**: Tailored to e-commerce review analysis",
        "**Business-Aligned**: Produces actionable insights", 
        "**Technically Sound**: Combines multiple ML/NLP techniques",
        "**Ethically Responsible**: Includes privacy protection",
        "**Scalable**: Can handle millions of reviews",
        "**Interpretable**: Stakeholders understand the approach"
    ]
    
    for i, reason in enumerate(reasons, 1):
        st.markdown(f"{i}. {reason}")
    
    st.success("""
    üí° **This methodology represents a production-ready, enterprise-grade approach to sentiment 
    analysis that balances technical sophistication with business practicality.**
    """)

# Sidebar analytics
st.sidebar.markdown("---")
st.sidebar.markdown("### üìä Quick Stats")
st.sidebar.metric("Active Filters", len([x for x in [sentiments, selected_products] if x]))
st.sidebar.metric("Data Filtered", f"{(len(filtered)/len(df)*100):.1f}%")

if st.sidebar.button("üîÑ Refresh Data"):
    st.cache_data.clear()
    st.experimental_rerun()
